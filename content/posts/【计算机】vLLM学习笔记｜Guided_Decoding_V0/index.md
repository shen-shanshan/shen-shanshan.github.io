---
title: 'vLLM å­¦ä¹ ç¬”è®°ï½œGuided Decoding'
date: '2025-03-20T11:44:20+08:00'
categories: "è®¡ç®—æœº"
tags: ["AI", "LLM", "æ¨¡å‹æ¨ç†", "vLLM", "æºç åˆ†æ"]
# summary: "xxx"
# draft: false
---

## ä¸€ã€å¼•è¨€

ç›®å‰ï¼Œåœ¨å¤§æ¨¡å‹æ¨ç†é¢†åŸŸä¸­ï¼ŒGuided Decoding æŠ€æœ¯å¹¿æ³›ç”¨äºç”Ÿæˆä¸€äº›ç‰¹å®šæ ¼å¼çš„è¾“å‡ºï¼Œå¦‚ï¼šSQLã€JSON ç­‰ã€‚æœ¬æ–‡å°†åŸºäº vLLM ä»¥åŠ Outlines åç«¯ï¼Œæ·±å…¥è§£æ Guided Decoding èƒŒåçš„æŠ€æœ¯åŸç†ã€‚

## äºŒã€ä»€ä¹ˆæ˜¯ Guided Decodingï¼Ÿ

ä¸€èˆ¬æ¥è¯´ï¼ŒLLM çš„è¾“å‡ºé€šå¸¸æ˜¯ä¸€æ®µç¬¦åˆäººç±»è¡¨è¾¾ä¹ æƒ¯çš„æ–‡æœ¬åºåˆ—ï¼Œè¿™è®©æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ LLM æ¥å›ç­”é—®é¢˜æˆ–æ˜¯åˆ›ä½œå†…å®¹ã€‚ç„¶è€Œï¼Œå½“æˆ‘ä»¬éœ€è¦ LLM çš„è¾“å‡ºç¬¦åˆç‰¹å®šçš„æ ¼å¼ï¼ˆå¦‚ï¼šJSONã€SQLã€æ­£åˆ™è¡¨è¾¾å¼ç­‰ï¼‰æ—¶â€”â€”ä¾‹å¦‚å¸Œæœ› LLM æ ¹æ®æˆ‘ä»¬çš„éœ€æ±‚ç”ŸæˆæŸ¥è¯¢æ•°æ®åº“çš„ SQL è¯­å¥ï¼Œé€šè¿‡å¾®è°ƒçš„æ–¹æ³•é€šå¸¸å¾ˆéš¾è¾¾åˆ°æˆ‘ä»¬é¢„æœŸçš„æ•ˆæœã€‚è¿™æ—¶ï¼Œå°±éœ€è¦ç”¨åˆ° Guided Decoding æŠ€æœ¯ï¼Œå®ƒå¯ä»¥é€šè¿‡å½±å“æ¨¡å‹è¾“å‡ºå±‚çš„ Logits åˆ†å¸ƒï¼ˆæ–½åŠ  Mask è¿‡æ»¤ä¸æ»¡è¶³è¦æ±‚çš„ Tokenï¼‰æ¥è¾¾åˆ°è§„èŒƒæ¨¡å‹è¾“å‡ºæ ¼å¼çš„æ•ˆæœã€‚

**ğŸŒ° ä¸¾ä¸ªä¾‹å­ï¼š**

æˆ‘ä»¬å¯ä»¥å‘ LLM è¾“å…¥ä¸€ä¸ª Prompt ä»¥åŠå¯¹åº”çš„æ ¼å¼æ•°æ®ï¼š

```python
# Guided decoding by JSON using Pydantic schema
class CarType(str, Enum):
    sedan = "sedan"
    suv = "SUV"
    truck = "Truck"
    coupe = "Coupe"


class CarDescription(BaseModel):
    brand: str
    model: str
    car_type: CarType


json_schema = CarDescription.model_json_schema()


prompt = ("Generate a JSON with the brand, model and car_type of"
          "the most iconic car from the 90's, think in 100 tokens")
```

æ­¤æ—¶ï¼ŒLLM å°±ä¼šæ ¹æ®æˆ‘ä»¬çš„è¦æ±‚ç”Ÿæˆä¸€ä¸ª JSON æ ¼å¼çš„è¾“å‡ºï¼š

```json
content: {
    "brand": "Levels",
    "model": "racing equation",
    "car_type": "sedan"
}
```

## ä¸‰ã€Outlines åŸç†è¯¦è§£

ç›®å‰ï¼Œå®ç°äº† Guided Decoding æ”¯æŒçš„åç«¯æœ‰ `outlines`ã€`xgrammar` ä»¥åŠ `lm-format-enforcer` ç­‰ï¼Œä¸‹é¢å°†ä»¥ Outlines ä¸ºä¾‹ï¼Œæ·±å…¥ä»‹ç» Guided Decoding èƒŒåçš„å®ç°åŸç†ã€‚

**Outlines çš„æ ¸å¿ƒæŠ€æœ¯ç‚¹åŒ…æ‹¬ï¼š**

- **åŸºäº FSMï¼ˆFinite-State Machineï¼Œæœ‰é™çŠ¶æ€æœºï¼‰**ï¼Œå®ç°äº†å½“å‰è¾“å…¥ä¸å¯¹åº”çŠ¶æ€çš„åŒ¹é…ï¼Œå¹¶å¯ä»¥æ ¹æ®çŠ¶æ€è½¬ç§»å‡½æ•°ç¡®å®šå¯¹åº”çš„ Maskï¼›
- **å»ºç«‹äº† FSM çš„çŠ¶æ€ä¸å…¶å¯æ¥å— Token çš„ Map**ï¼Œå¹¶ä¸ºè¿™äº› Token å»ºç«‹ç´¢å¼•ï¼Œä»è€Œé¿å…äº†åœ¨æ¯æ¬¡ Decode ä¸­éå†æ•´ä¸ª Vocabulary è¿›è¡ŒåŒ¹é…ï¼ŒåŠ å¿«äº†åŒ¹é…çš„é€Ÿåº¦ã€‚

![](./images/fsm.png)

ä¸‹é¢ï¼Œä¸ºäº†è®©å¤§å®¶æ›´å¿«é€Ÿã€æ›´ç›´è§‚åœ°ç†è§£ Outlines çš„åŸç†ï¼Œæœ¬æ–‡å°†å°½åŠ›é¿å…å¤§æ®µå…¬å¼å’Œç®—æ³•çš„ç½—åˆ—ï¼Œè€Œæ˜¯å°½é‡ä½¿ç”¨å…·ä½“çš„ä¾‹å­è¿›è¡Œè®²è§£ã€‚

### 3.1 FSM çš„å·¥ä½œåŸç†

**ğŸŒ° ä¸¾ä¸ªä¾‹å­ï¼š**

å‡è®¾æˆ‘ä»¬éœ€è¦æ¨¡å‹è¾“å‡ºä¸€ä¸ªæµ®ç‚¹å°æ•°ï¼Œå³è¾“å‡ºéœ€è¦åŒ¹é…çš„æ­£åˆ™è¡¨è¾¾å¼ä¸º `([0-9]*)?\.?[0-9]*`ï¼Œå¹¶ç»™å®šä¸€ä¸ªä»…åŒ…å« `A`ã€`.`ã€`42`ã€`.2` å’Œ `1` çš„ Vocabularyã€‚

> â€œæ­£åˆ™è¡¨è¾¾å¼â€ç¬¦å·è¯´æ˜ï¼š
>
> - `*`ï¼šåŒ¹é…å‰é¢çš„å­è¡¨è¾¾å¼é›¶æ¬¡æˆ–å¤šæ¬¡ï¼›
> - `?`ï¼šåŒ¹é…å‰é¢çš„å­è¡¨è¾¾å¼é›¶æ¬¡æˆ–ä¸€æ¬¡ï¼›
> - `.`ï¼šåŒ¹é…é™¤æ¢è¡Œç¬¦ `\n` ä¹‹å¤–çš„ä»»ä½•å•å­—ç¬¦ï¼›
> - `\.`ï¼šåŒ¹é…å°æ•°ç‚¹ç¬¦å· `.`ï¼ˆéœ€è¦ä½¿ç”¨ `\` è¿›è¡Œè½¬ä¹‰ï¼‰ã€‚

å½“ LLM å¼€å§‹ Decode æ—¶ï¼ŒFSM ä½äºåˆå§‹çŠ¶æ€ï¼ˆ`0`ï¼Œç”¨æ•´æ•°è¡¨ç¤ºä¸åŒçš„çŠ¶æ€ï¼‰ï¼Œæ ¹æ®çŠ¶æ€ `0` çš„è½¬ç§»å‡½æ•°å¯çŸ¥ï¼Œå½“å‰çŠ¶æ€å¯ä»¥æ¥å—çš„å­—ç¬¦æ¨¡å¼ä¸º `[0-9]` å’Œ `[.]`ï¼Œè€Œåœ¨æˆ‘ä»¬æ‰€ç»™çš„è¯è¡¨ä¸­ï¼Œåªæœ‰ `A` ä¸ç¬¦åˆï¼Œæ­¤æ—¶ FSM ä¼šé’ˆå¯¹è¯è¡¨ `['A', '.', '42', '.2', '1']` ç”Ÿæˆä¸€ä¸ªå€¼ä¸º `[0, 1, 1, 1, 1]` çš„ Maskï¼Œå³æ¨¡å‹åœ¨æœ¬è½®è¿­ä»£è¿›è¡Œé‡‡æ ·æ—¶ä¼šæ’é™¤æ‰ `A`ï¼ˆå›¾ä¸­ç”¨é»‘è‰²è¡¨ç¤ºï¼‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![](./images/outlines-fsm-1.png)

æ¥ä¸‹æ¥ï¼Œæœ‰ä¸¤ç§æƒ…å†µï¼š

1. **æ¨¡å‹æœ¬è½®çš„é‡‡æ ·å€¼ä¸º `.2`ï¼ˆå›¾ä¸­ç”¨çº¢è‰²è¡¨ç¤ºï¼‰**ï¼Œæ­¤æ—¶ `.2` åŒæ—¶æ»¡è¶³ä»çŠ¶æ€ `0` è¿‡æ¸¡åˆ°çŠ¶æ€ `2` å†åˆ°çŠ¶æ€ `3` çš„æ¡ä»¶ï¼Œå› æ­¤ FSM çš„å½“å‰çŠ¶æ€ä¼šè·³è½¬åˆ°çŠ¶æ€ `3` å¹¶ç”Ÿæˆä¸‹ä¸€æ¬¡é‡‡æ ·çš„ Maskã€‚ç”±äºçŠ¶æ€ `3` å¯æ¥å—çš„å­—ç¬¦æ¨¡å¼ä»…ä¸º `[0-9]`ï¼Œåªæœ‰ `42` å’Œ `1` æ»¡è¶³ï¼Œå› æ­¤æ­¤æ—¶çš„ Mask ä¸º `[0, 0, 1, 0, 1]`ï¼›
2. **æ¨¡å‹æœ¬è½®çš„é‡‡æ ·å€¼ä¸º `1`ï¼ˆå›¾ä¸­ç”¨é»„è‰²è¡¨ç¤ºï¼‰**ï¼ŒåŒç†ï¼Œæ­¤æ—¶ FSM ä¼šè·³è½¬åˆ°çŠ¶æ€ `1` å¹¶ç”Ÿæˆå¯¹åº”çš„ Maskï¼Œå…¶å€¼ä¸º `[0, 1, 1, 1, 1]`ã€‚

ä¸æ–­å¾ªç¯æ­¤è¿‡ç¨‹ï¼Œæœ€ç»ˆå°±èƒ½å¾—åˆ°æ»¡è¶³è¯¥æ­£åˆ™è¡¨è¾¾å¼çš„è¾“å‡ºã€‚

> è¡¥å……ï¼šåœ¨ vLLM çš„å®ç°ä¸­ï¼Œå…¶ Mask ä½¿ç”¨ `0` è¡¨ç¤ºæ¥å—çš„ Tokenï¼Œç”¨ `-inf`ï¼ˆè´Ÿæ— ç©·ï¼‰è¡¨ç¤ºè¦æ’é™¤çš„ Tokenï¼Œç„¶åå†å°†è¾“å‡ºçš„ Logits åˆ†å¸ƒä¸ Mask ç›¸åŠ ï¼Œä»è€Œè¾¾åˆ°å±è”½ä¸æ»¡è¶³è¦æ±‚çš„ Token çš„æ•ˆæœã€‚

### 3.2 FSM çš„æ„å»ºè¿‡ç¨‹

åœ¨äº†è§£äº† Outlines ä¸­ FSM çš„åŸºæœ¬å·¥ä½œåŸç†ä¹‹åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å†çœ‹ä¸‹ï¼Œé’ˆå¯¹ä¸€ä¸ªç»™å®šçš„æ­£åˆ™è¡¨è¾¾å¼ä¸ Vocabularyï¼ŒOutlines æ˜¯å¦‚ä½•æ„å»ºè¿™ä¸ª FSM çš„ã€‚

FSM çš„æ„å»ºè¿‡ç¨‹ä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼š

1. **æ”¶é›†æ¯ä¸ª Token èƒ½å¤ŸåŒ¹é…çš„çŠ¶æ€è½¬æ¢è·¯å¾„**ï¼šç»™å®šä¸€ä¸ª Tokenï¼Œéå†æ‰€æœ‰çŠ¶æ€ï¼Œå¹¶ä»æ¯ä¸€ä¸ªçŠ¶æ€å¼€å§‹ï¼Œçœ‹æ˜¯å¦å­˜åœ¨èƒ½å¤Ÿå®Œæ•´æ¥å—è¯¥ Token çš„è·¯å¾„ï¼Œè‹¥å­˜åœ¨ï¼Œåˆ™å°†è¯¥è·¯å¾„è®°å½•åˆ°è¯¥ Token å¯¹åº”çš„åˆ—è¡¨ä¸­ï¼›è‹¥ä¸å­˜åœ¨è¿™æ ·ä¸€æ¡è·¯å¾„ï¼Œåˆ™è·³è¿‡å½“å‰çŠ¶æ€ï¼Œç»§ç»­æ”¶é›†ä»¥ä¸‹ä¸€ä¸ªçŠ¶æ€ä½œä¸ºå¼€å§‹çŠ¶æ€çš„å¯èƒ½è·¯å¾„ï¼›
2. **æ”¶é›†æ¯ä¸ªçŠ¶æ€èƒ½å¤Ÿæ¥å—çš„æ‰€æœ‰ Token**ï¼šéå†æ¯ä¸€ä¸ª Tokenï¼Œå¹¶é’ˆå¯¹è¯¥ Token æ‰§è¡Œæ­¥éª¤ä¸€ï¼Œè·å–è¯¥ Token èƒ½å¤ŸåŒ¹é…çš„çŠ¶æ€è½¬æ¢è·¯å¾„ï¼Œç„¶åéå†æ¯ä¸€æ¡è·¯å¾„å¹¶å–è·¯å¾„ä¸­çš„ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆå¼€å§‹çŠ¶æ€ï¼‰ï¼Œå°†è¯¥çŠ¶æ€ä¸è¯¥ Token è¿›è¡Œç»‘å®šï¼ˆå°†è¯¥ Token æ·»åŠ åˆ°è¯¥çŠ¶æ€çš„é›†åˆä¸­ï¼‰ã€‚

**ğŸŒ° ä¸¾ä¸ªä¾‹å­ï¼š**

è¿™é‡Œæˆ‘ä»¬ç»§ç»­ä½¿ç”¨ä¸Šé¢çš„ä¾‹å­è¿›è¡Œè¯´æ˜ï¼š

![](./images/outlines-fsm-2.png)

**å¯¹äº Token `A`ï¼Œéå†æ¯ä¸ªçŠ¶æ€ï¼š**

1. ä»çŠ¶æ€ `0` å¼€å§‹ï¼Œä¸æ»¡è¶³ï¼Œpassï¼›
2. ä»çŠ¶æ€ `1` å¼€å§‹ï¼Œä¸æ»¡è¶³ï¼Œpassï¼›
3. ä»çŠ¶æ€ `2` å¼€å§‹ï¼Œä¸æ»¡è¶³ï¼Œpassï¼›
4. ä»çŠ¶æ€ `3` å¼€å§‹ï¼Œä¸æ»¡è¶³ï¼Œpassã€‚

**å¯¹äº Token `.`ï¼Œéå†æ¯ä¸ªçŠ¶æ€ï¼š**

1. ä»çŠ¶æ€ `0` å¼€å§‹ï¼Œå¯ä»¥è½¬æ¢åˆ°çŠ¶æ€ `2`ï¼Œè®°å½•è·¯å¾„ `0 -> 2`ï¼›
2. ä»çŠ¶æ€ `1` å¼€å§‹ï¼Œå¯ä»¥è½¬æ¢åˆ°çŠ¶æ€ `2`ï¼Œè®°å½•è·¯å¾„ `1 -> 2`ï¼›
3. ä»çŠ¶æ€ `2` å¼€å§‹ï¼Œä¸æ»¡è¶³ï¼Œpassï¼›
4. ä»çŠ¶æ€ `3` å¼€å§‹ï¼Œä¸æ»¡è¶³ï¼Œpassã€‚

æ­¤æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æ”¶é›†åˆ°å¯¹äº Token `.`ï¼Œå…¶æ‰€èƒ½åŒ¹é…åˆ°çš„æ‰€æœ‰çŠ¶æ€è½¬æ¢è·¯å¾„é›†åˆï¼š

```
0 -> 2
1 -> 2
```

ç„¶åï¼Œå°†æ¯æ¡è·¯å¾„çš„èµ·å§‹çŠ¶æ€ä¸è¯¥ Token è¿›è¡Œç»‘å®šï¼ˆä¸€ä¸ª HashMapï¼‰ï¼š

```
çŠ¶æ€ 0 <-> set(".")
çŠ¶æ€ 1 <-> set(".")
```

**å¯¹äº Token `42`ï¼Œéå†æ¯ä¸ªçŠ¶æ€ï¼š**

1. ä»çŠ¶æ€ `0` å¼€å§‹ï¼Œå¯ä»¥è½¬æ¢åˆ°çŠ¶æ€ `1`ï¼Œè®°å½•è·¯å¾„ `0 -> 1`ï¼›
2. ä»çŠ¶æ€ `1` å¼€å§‹ï¼Œå¯ä»¥è½¬æ¢åˆ°çŠ¶æ€ `1`ï¼Œè®°å½•è·¯å¾„ `1`ï¼›
3. ä»çŠ¶æ€ `2` å¼€å§‹ï¼Œå¯ä»¥è½¬æ¢åˆ°çŠ¶æ€ `3`ï¼Œè®°å½•è·¯å¾„ `2 -> 3`ï¼›
4. ä»çŠ¶æ€ `3` å¼€å§‹ï¼Œå¯ä»¥è½¬æ¢åˆ°çŠ¶æ€ `3`ï¼Œè®°å½•è·¯å¾„ `3`ã€‚

Token `42` èƒ½åŒ¹é…åˆ°çš„æ‰€æœ‰è·¯å¾„é›†åˆå¦‚ä¸‹ï¼š

```
0 -> 1
1
2 -> 3
3
```

åŒç†ï¼Œå°†æ‰€æœ‰èµ·å§‹çŠ¶æ€ä¸è¯¥ Token è¿›è¡Œç»‘å®šï¼š

```
çŠ¶æ€ 0 <-> set(".", "42")
çŠ¶æ€ 1 <-> set(".", "42")
çŠ¶æ€ 2 <-> set("42")
çŠ¶æ€ 3 <-> set("42")
```

**å¯¹äº Token `.2`ï¼Œéå†æ¯ä¸ªçŠ¶æ€ï¼š**

1. ä»çŠ¶æ€ `0` å¼€å§‹ï¼Œè®°å½•è·¯å¾„ `0 -> 2 -> 3`ï¼›
2. ä»çŠ¶æ€ `1` å¼€å§‹ï¼Œè®°å½•è·¯å¾„ `1 -> 2 -> 3`ï¼›
3. ä»çŠ¶æ€ `2` å¼€å§‹ï¼Œä¸æ»¡è¶³ï¼Œpassï¼›
4. ä»çŠ¶æ€ `3` å¼€å§‹ï¼Œä¸æ»¡è¶³ï¼Œpassã€‚

ç»‘å®šçŠ¶æ€ä¸ Tokenï¼š

```
çŠ¶æ€ 0 <-> set(".", "42", ".2")
çŠ¶æ€ 1 <-> set(".", "42", ".2")
çŠ¶æ€ 2 <-> set("42")
çŠ¶æ€ 3 <-> set("42")
```

**å¯¹äº Token `1`ï¼Œéå†æ¯ä¸ªçŠ¶æ€ï¼š**

1. ä»çŠ¶æ€ `0` å¼€å§‹ï¼Œè®°å½•è·¯å¾„ `0 -> 1`ï¼›
2. ä»çŠ¶æ€ `1` å¼€å§‹ï¼Œè®°å½•è·¯å¾„ `1`ï¼›
3. ä»çŠ¶æ€ `2` å¼€å§‹ï¼Œè®°å½•è·¯å¾„ `2 -> 3`ï¼›
4. ä»çŠ¶æ€ `3` å¼€å§‹ï¼Œè®°å½•è·¯å¾„ `3`ã€‚

ç»‘å®šçŠ¶æ€ä¸ Tokenï¼š

```
çŠ¶æ€ 0 <-> set(".", "42", ".2", "1")
çŠ¶æ€ 1 <-> set(".", "42", ".2", "1")
çŠ¶æ€ 2 <-> set("42", "1")
çŠ¶æ€ 3 <-> set("42", "1")
```

æœ€åï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†æ¯ä¸ª FSM çŠ¶æ€èƒ½å¤ŸåŒ¹é…çš„æ‰€æœ‰ Token é›†åˆã€‚

åœ¨å®é™…è¿‡ç¨‹ä¸­ï¼Œå½“ LLM ç”Ÿæˆçš„å†…å®¹è¿›è¡Œåˆ°æŸä¸€ä¸ªçŠ¶æ€æ—¶ï¼ˆæ¯”å¦‚ï¼šçŠ¶æ€ `2`ï¼‰ï¼ŒOutlines å°±èƒ½å¿«é€Ÿé€šè¿‡è¯¥ Map è·å–åˆ°å½“å‰çŠ¶æ€æ‰€èƒ½æ¥å—ç”Ÿæˆçš„ Token é›†åˆï¼ˆ`42` å’Œ `1`ï¼‰ï¼Œæœç´¢çš„æ—¶é—´å¤æ‚åº¦ä¸º `O(1)`ï¼Œå¹¶ç”Ÿæˆä¸‹ä¸€æ­¥ Decode çš„ Maskï¼ˆä¸º `[0, 0, 1, 0, 1]`ï¼Œå³è¿‡æ»¤æ‰äº†å…¶å®ƒ 3 ä¸ª Tokenï¼‰ã€‚

### 3.3 æ€»ç»“

**Outlines çš„ä¼˜ç¼ºç‚¹ï¼š**

- **ä¼˜ç‚¹ï¼šä¸ä¼šå¼•å…¥é¢å¤–çš„æ¨ç†å»¶è¿Ÿ**ã€‚FSM Map çš„æ„å»ºè¿‡ç¨‹ä¼šåœ¨çœŸæ­£è¿›è¡Œ Decode ä¹‹å‰å°±å®Œæˆï¼Œå› æ­¤å¹¶ä¸ä¼šç»™å®é™…è¿è¡Œæ—¶çš„æ¨ç†è¿‡ç¨‹å¼•å…¥å¤ªå¤šé¢å¤–çš„å»¶è¿Ÿï¼ˆå¼•å…¥çš„é¢å¤–è®¡ç®—ä»…åŒ…æ‹¬ç”Ÿæˆ Mask ç­‰ï¼Œå‡ ä¹å¯ä»¥å¿½ç•¥ï¼‰ï¼›
- **ç¼ºç‚¹ï¼šä¼šå¼•å…¥é¢å¤–çš„å†…å­˜å ç”¨**ã€‚ä¿å­˜å¹¶åŠ è½½è¿™ä¸ª Map ä¼šå¸¦æ¥é¢å¤–çš„å†…å­˜å ç”¨ï¼Œå› æ­¤åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¨ç†é€Ÿåº¦å’Œå†…å­˜å ç”¨è¿™ä¸¤æ–¹é¢åšä¸€ä¸ªæƒè¡¡ã€‚

å¦å¤–ï¼ŒOutlines ä¸ä»…å¯ä»¥æ”¯æŒä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥é™å®šæ¨¡å‹çš„è¾“å‡ºï¼Œè¿˜æ”¯æŒ **CFGsï¼ˆContext-Free Grammarsï¼Œä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ï¼‰**ï¼Œæ¯”å¦‚ï¼šJSONã€SQL ä»¥åŠ Python ç­‰è¯­è¨€ã€‚å…³äº CFGs ç”Ÿæˆçš„åŸç†ï¼Œè¿™é‡Œä¸å†è¯¦ç»†å±•å¼€ï¼Œæ„Ÿå…´è¶£çš„è¯»è€…å¯ä»¥è‡ªè¡Œé˜…è¯» Outlines çš„[<u>è®ºæ–‡</u>](https://arxiv.org/abs/2307.09702)ä¸[<u>æºç </u>](https://github.com/dottxt-ai/outlines)ã€‚

## å››ã€vLLM Guided Decoding æºç è§£è¯»

ç›®å‰ï¼ŒvLLM çš„ Guided Decoding åŠŸèƒ½æ”¯æŒ `outlines`ã€`xgrammar` ä»¥åŠ `lm-format-enforcer` è¿™ä¸‰ç§åç«¯ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `Qwen2.5-7B-Instruct` æ¨¡å‹ï¼Œå¹¶åŸºäº `outlines` åç«¯ï¼Œè¯¦ç»†è®²è§£ Guided Decoding çš„æ•´ä½“æµç¨‹åŠå…¶ä»£ç å®ç°ã€‚

### 4.1 åŠ è½½ LogitsProcessor

å½“ `LLMEngine` åˆå§‹åŒ–æ—¶ï¼Œä¼šåœ¨ `_build_logits_processors()` æ–¹æ³•ä¸­è°ƒç”¨ `get_local_guided_decoding_logits_processor()` æ–¹æ³•è·å–å½“å‰å¯ç”¨åç«¯å¯¹åº”çš„ `LogitsProcessor`ï¼ˆä½äº `vllm/model_executor/guided_decoding` ç›®å½•ä¸‹ï¼‰ã€‚

æ­¤æ—¶ï¼Œéœ€è¦ä¼ å…¥ Guided Decoding ç›¸å…³çš„å‚æ•° `GuidedDecodingParams`ï¼Œè¿™äº›å‚æ•°ä½äº `SamplingParams` ä¸­ï¼Œå¯ä»¥åœ¨å¯åŠ¨ vLLM æ—¶è¿›è¡ŒæŒ‡å®šã€‚æœ€åï¼Œæ‰€æœ‰è¢«æˆåŠŸåŠ è½½çš„å„ç§ `LogitsProcessor` éƒ½ä¼šè¢«å­˜æ”¾åˆ° `SamplingParams` ä¸­ã€‚

éƒ¨åˆ†ä»£ç å¦‚ä¸‹ï¼š

```python
# llm_engine.py
def _build_logits_processors(..., sampling_params, ...):

    logits_processors = []

    if sampling_params.guided_decoding is not None:
        # ...
        guided_decoding = sampling_params.guided_decoding
        # ...
        processor = get_local_guided_decoding_logits_processor(
            guided_params=guided_decoding,
            tokenizer=tokenizer,
            model_config=self.model_config,
            reasoning_backend=self.decoding_config.reasoning_backend,
        )
        if processor:
            logits_processors.append(processor)
    
    # ...

    sampling_params.logits_processors.extend(logits_processors)
    return sampling_params
```

`GuidedDecodingParams` åŒ…å«çš„å‚æ•°å¦‚ä¸‹ï¼š

```python
# sampling_params.py
@dataclass
class GuidedDecodingParams:
    """One of these fields will be used to build a logit processor."""
    json: Optional[Union[str, dict]] = None
    regex: Optional[str] = None
    choice: Optional[list[str]] = None
    grammar: Optional[str] = None
    json_object: Optional[bool] = None
    """These are other options that can be set"""
    backend: Optional[str] = None
    whitespace_pattern: Optional[str] = None
```

å…¶ä¸­ï¼Œå‰ 5 ä¸ªå‚æ•°ç”¨äºæŒ‡å®šæ¨¡å‹è¾“å‡ºéœ€è¦åŒ¹é…çš„æ¨¡å¼ï¼Œå‰©ä¸‹ 2 ä¸ªå‚æ•°ä¸ºä¸€äº›å¯é€‰é…ç½®ã€‚

### 4.2 æ•´ä½“æ¨ç†æµç¨‹

å½“åˆå§‹åŒ–å®Œæˆåï¼ŒvLLM ä¼šå¼€å¯ä¸€ä¸ªå¾ªç¯å¹¶ä¸æ–­è°ƒç”¨ `step()` æ–¹æ³•æ‰§è¡Œæ¨ç†ï¼Œæ¯ä¸€æ¬¡è°ƒç”¨å°±æ˜¯ä¸€ä¸ªè¿­ä»£ã€‚

éƒ¨åˆ†ä»£ç å¦‚ä¸‹ï¼š

```python
# llm.py
def _run_engine(...):
    # ...
    while self.llm_engine.has_unfinished_requests():
        step_outputs = self.llm_engine.step()
        # ...
    
    return outputs
```

åœ¨ `step()` æ–¹æ³•ä¸­ï¼ŒvLLM çš„æ•´ä½“è°ƒç”¨é“¾è·¯å¦‚ä¸‹ï¼š

![](./images/process-1.png)

å…¶ä¸­ï¼Œä¸ Guided Decoding æœ‰å…³çš„æ ¸å¿ƒå¤„ç†é€»è¾‘éƒ½è¢«å°è£…åˆ°äº† `BaseLogitsProcessor` çš„ `__call__()` æ–¹æ³•ä¸­ï¼Œè¿™æ ·å°±å¯ä»¥ç›´æ¥é€šè¿‡ `logits_processor(...)` çš„æ–¹å¼æ¥è¿›è¡Œè°ƒç”¨ã€‚

### 4.3 è®¡ç®— Mask

å…·ä½“åœ°ï¼Œ`BaseLogitsProcessor: __call__()` çš„éƒ¨åˆ†ä»£ç ï¼ˆ`#...` ä»£è¡¨çœç•¥ï¼‰åŠå…¶è¯´æ˜å¦‚ä¸‹ï¼š

```python
from outlines.fsm.guide import (CFGGuide, CFGState, Generate, Guide,
                                RegexGuide, Write)


class BaseLogitsProcessor:

    def __init__(self, guide: Guide, reasoner: Optional[Reasoner]):
        self._guide: Guide = guide
        self._fsm_state: DefaultDict[int, Union[int, CFGState]] = defaultdict(int)
        # ...

    def __call__(self, input_ids: List[int],
                 scores: torch.Tensor) -> torch.Tensor:
        """Use the FSM to bias the logits before sampling the next token."""
        # ...

        seq_id = hash(tuple(input_ids))

        if len(input_ids) > 0:
            last_token = input_ids[-1]
            last_seq_id = hash(tuple(input_ids[:-1]))
            # æ ¹æ®å‰ä¸€ä¸ª FSM çŠ¶æ€ä»¥åŠå½“å‰è¾“å…¥çš„ Tokenï¼Œä» Outlines è·å–ä¸‹ä¸€ä¸ªçŠ¶æ€
            # _fsm_state æ˜¯ä¸€ä¸ª Mapï¼šåºåˆ—å“ˆå¸Œ <--> FSM çŠ¶æ€
            self._fsm_state[seq_id] = self._guide.get_next_state(
                state=self._fsm_state[last_seq_id], token_id=last_token)
        
        # ...

        # ä» Outlines è·å–å½“å‰çŠ¶æ€æ‰€èƒ½æ¥å—çš„ Token é›†åˆ
        instruction = self._guide.get_next_instruction(
            state=self._fsm_state[seq_id])
        allowed_tokens = instruction.tokens

        # ä½¿ç”¨ -torch.inf åˆå§‹åŒ– Mask
        mask = torch.full((scores.shape[-1], ),
                          -torch.inf,
                          device=scores.device)
        
        # ...

        # å°† Mask ä¸­ allowed_tokens çš„ä½ç½®è®¾ä¸º 0ï¼Œå…¶ä½™ä¸º -torch.infï¼ˆå³è¦è¢«è¿‡æ»¤çš„ï¼‰
        mask.index_fill_(0, allowed_tokens, 0)
        
        # å°† Mask åº”ç”¨åˆ°æ¨¡å‹è¾“å‡ºä¸Šï¼š
        # 1.å¯¹äºå¯æ¥å—çš„ Tokenï¼šåŸæœ¬çš„æ¦‚ç‡ + Mask(0)ï¼Œæ¦‚ç‡ä¸å˜
        # 2.å¯¹äºä¸æ¥å—çš„ Tokenï¼šåŸæœ¬çš„æ¦‚ç‡ + Mask(è´Ÿæ— ç©·)ï¼Œæ¦‚ç‡ä¸º 0
        scores.add_(mask)

        return scores
```

æ€»ç»“ï¼šGuided Decoding é€šè¿‡ä¸€ä¸ª Mask æœºåˆ¶å®ç°äº†ç­›é™¤æ¨¡å‹ç”Ÿæˆçš„ä¸æ»¡è¶³å½“å‰æ ¼å¼é™åˆ¶çš„ Token çš„æ•ˆæœã€‚

### 4.4 æ”¯æŒ Reasoning

ç›®å‰ï¼ŒvLLM è¿˜æ”¯æŒåœ¨ Reasoning æ—¶ï¼Œä»…å¯¹æœ€åçš„ç»“æœ `content` æ‰§è¡Œ Guided Decoding é€»è¾‘ï¼Œè€Œä¸å½±å“åŸæœ¬æ¨ç†éƒ¨åˆ†çš„å†…å®¹ `reasoning_content`ã€‚

å…·ä½“çš„ä»£ç å¯ä»¥å‚è€ƒè¿™ä¸ª [<u>PR</u>](https://github.com/vllm-project/vllm/pull/12955)ï¼Œç”± [<u>Ce Gao</u>](https://github.com/gaocegege) å®ç°ï¼Œæ„Ÿå…´è¶£çš„è¯»è€…å¯ä»¥è‡ªè¡Œäº†è§£ï¼Œè¿™é‡Œä¸å†è¯¦ç»†å±•å¼€ã€‚

## äº”ã€SGLang Jump-Forward Decoding

ä½¿ç”¨ FSM å®ç° Guided Decoding è¿˜æœ‰ä¸€ä¸ªç¼ºç‚¹â€”â€”å³åªèƒ½é€ä¸ª Token è®¡ç®— Maskã€‚ç„¶è€Œï¼Œåœ¨ Guided Decoding ä¸­ï¼Œæœ‰ä¸€äº›ç‰¹å®šçš„ Token ç»„åˆæ˜¯ç»‘å®šåœ¨ä¸€èµ·çš„ï¼Œå¯¹äºè¿™äº› Tokenï¼Œå…¶å®æ²¡å¿…è¦å†ä¸€ä¸ªä¸€ä¸ªåœ°å»ç”Ÿæˆï¼Œè€Œæ˜¯å¯ä»¥ä¸€æ¬¡ Decode ç›´æ¥ç”Ÿæˆå‡ ä¸ª Token çš„ç»„åˆï¼Œä»è€Œå¯ä»¥åŠ é€Ÿ Guided Decoding çš„æ¨ç†è¿‡ç¨‹ã€‚

ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼ŒSGLang æå‡ºäº†ä¸€ç§åŸºäº **Compressed Finite State Machine** çš„ **Jump-Forward Decoding**ã€‚å³å½“ç”Ÿæˆä¸€äº›ç‰¹å®šçš„ Tokenï¼ˆåç»­æ¨¡å¼å›ºå®šä¸”å¯é¢„æµ‹ï¼Œå¦‚ï¼š`{`ï¼‰æ—¶ï¼Œè¯¥ç®—æ³•å¯ä»¥åœ¨ä¸€æ¬¡ Decode ä¸­å°†è¿ç»­çš„å‡ ä¸ª Token ç›´æ¥ç”Ÿæˆã€‚

![](./images/jump-forwad.png)

å…·ä½“åœ°ï¼ŒCompressed FSM é€šè¿‡å…ˆåˆ†æ FSMï¼ˆæ ¹æ®ç”¨æˆ·ç»™å®šçš„æ­£åˆ™è¡¨è¾¾å¼ç”Ÿæˆï¼‰ï¼Œè¯†åˆ«å…¶ä¸­ä¸€äº›æ²¡æœ‰åˆ†æ”¯çš„èŠ‚ç‚¹ï¼ˆå³åªç”±ä¸€æ¡è¾¹è¿æ¥ï¼‰ï¼Œå¹¶å°†è¿™äº›è·¯å¾„ä¸Šçš„èŠ‚ç‚¹åˆå¹¶ï¼Œä»è€Œå¯ä»¥é€šè¿‡ä¸€æ¬¡è·³è½¬ï¼ˆDecodeï¼‰ï¼Œè·¨è¶Šå¤šä¸ªçŠ¶æ€ï¼ˆTokenï¼‰ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªå…·æœ‰åˆ†æ”¯çš„èŠ‚ç‚¹ï¼Œä»è€Œæå¤§åœ°æé«˜äº† Guided Decoding çš„æ•ˆç‡ã€‚

æ›´å¤šç»†èŠ‚å¯ä»¥å‚è€ƒ SGLang çš„[<u>è®ºæ–‡</u>](https://arxiv.org/abs/2312.07104)å’Œ[<u>ä»£ç </u>](https://github.com/sgl-project/sglang)ã€‚

## å…­ã€å‚è€ƒèµ„æ–™

- [<u>Robust Text-to-SQL Generation with Execution-Guided Decoding</u>](https://arxiv.org/abs/1807.03100)
- [<u>Efficient Guided Generation for Large Language Models</u>](https://arxiv.org/abs/2307.09702)
- [<u>vLLM Docs | Structured Outputs</u>](https://docs.vllm.ai/en/stable/features/structured_outputs.html#structured-outputs)
- [<u>vLLM GitHub</u>](https://github.com/vllm-project/vllm)
- [<u>Fast JSON Decoding for Local LLMs with Compressed Finite State Machine</u>](https://lmsys.org/blog/2024-02-05-compressed-fsm/)
- [<u>SGLang: Efficient Execution of Structured Language Model Programs</u>](https://arxiv.org/abs/2312.07104)
