<!DOCTYPE html>
<html lang="en" dir="ltr" class="scroll-smooth" data-default-appearance="dark"
  data-auto-appearance="true"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>大模型微调知识全景 &middot; Home</title>
  <meta name="title" content="大模型微调知识全景 &middot; Home" />
  
  
  <meta name="keywords" content="AI, LLM, 模型微调, 论文精读, " />
  
  
  <link rel="canonical" href="http://localhost:1313/articles/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9F%A5%E8%AF%86%E5%85%A8%E6%99%AF/" />
  
  
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/css/main.bundle.min.c7683369d42ab0fa43c2faab379ff224b7030c0e984512cb4535d4888fb382e395322f3ef135ac80c0de62846aad770528c8a3cc249062ca58b1fb90c095bbcd.css"
    integrity="sha512-x2gzadQqsPpDwvqrN5/yJLcDDA6YRRLLRTXUiI&#43;zguOVMi8&#43;8TWsgMDeYoRqrXcFKMijzCSQYspYsfuQwJW7zQ==" />
  
  
  <script type="text/javascript" src="/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.a2d78d78672e549fbfc972ece871725b5478ba0b65708dda20cb97ab80a865eae6d247e1b05a4aec6ebbf78647ec3233bad8b2609ed98eee53cd58aa17128bc7.js"
    integrity="sha512-oteNeGcuVJ&#43;/yXLs6HFyW1R4ugtlcI3aIMuXq4CoZerm0kfhsFpK7G6794ZH7DIzutiyYJ7Zju5TzViqFxKLxw==" data-copy="" data-copied=""></script>
  
  
  
  <script src="/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js" integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S&#43;Yti0U7QtuZvQ=="></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/articles/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9F%A5%E8%AF%86%E5%85%A8%E6%99%AF/">
  <meta property="og:site_name" content="Home">
  <meta property="og:title" content="大模型微调知识全景">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-12-05T10:00:40+08:00">
    <meta property="article:modified_time" content="2024-12-05T10:00:40+08:00">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="模型微调">
    <meta property="article:tag" content="论文精读">
    <meta property="og:image" content="http://localhost:1313/articles/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9F%A5%E8%AF%86%E5%85%A8%E6%99%AF/featured.jpg">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/articles/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9F%A5%E8%AF%86%E5%85%A8%E6%99%AF/featured.jpg">
  <meta name="twitter:title" content="大模型微调知识全景">

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Articles",
    "name": "大模型微调知识全景",
    "headline": "大模型微调知识全景",
    
    
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/articles\/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9F%A5%E8%AF%86%E5%85%A8%E6%99%AF\/",
    "author" : {
      "@type": "Person",
      "name": "Shanshan Shen"
    },
    "copyrightYear": "2024",
    "dateCreated": "2024-12-05T10:00:40\u002b08:00",
    "datePublished": "2024-12-05T10:00:40\u002b08:00",
    
    "dateModified": "2024-12-05T10:00:40\u002b08:00",
    
    "keywords": ["AI","LLM","模型微调","论文精读"],
    
    "mainEntityOfPage": "true",
    "wordCount": "866"
  }]
  </script>


  
  
  <meta name="author" content="Shanshan Shen" />
  
  
  
  <link href="https://github.com/shen-shanshan" rel="me" />
  
  
  <link href="https://www.zhihu.com/people/sss-53-26" rel="me" />
  
  
  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>






















  
  



  
  
  <meta name="theme-color"/>
  
  
</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div class="min-h-[148px]"></div>
<div class="fixed inset-x-0 min-h-[130px] opacity-65 pl-[24px] pr-[24px] bg-gradient-to-b from-neutral from-60% dark:from-neutral-800 to-transparent mix-blend-normal" style="z-index:80"></div>
<div class="fixed inset-x-0 pl-[24px] pr-[24px]" style="z-index:100">
  <div id="menu-blur" class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div>
  <div class="relative max-w-[64rem] ml-auto mr-auto">
    <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3">
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/" class="text-base font-medium text-gray-500 hover:text-gray-900">Home</a>
            

        </nav>
        <nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12">

            
            
            
  <a href="/guide/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Guide
    </p>
</a>



            
            
  <a href="/about/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        About
    </p>
</a>



            
            
  <a href="/articles/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Articles
    </p>
</a>



            
            
  <a href="/categories/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Categories
    </p>
</a>



            
            
  <a href="/tags/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Tags
    </p>
</a>



            
            

            


            
            <button id="search-button" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            


            
            
            <div
                class="ltr:mr-14 rtl:ml-14 flex items-center">
                <button id="appearance-switcher" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400">
                    <div class="flex items-center justify-center dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </nav>
        <div class="flex md:hidden items-center space-x-5 md:ml-12 h-12">

            <span></span>

            


            
            <button id="search-button-mobile" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            <button id="appearance-switcher-mobile" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400" style="margin-right:5px">
                <div class="flex items-center justify-center dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 -mr-2 md:hidden">

        <label id="menu-button" class="block">
            
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:5px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl">

                    <li id="menu-close-button">
                        <span
                            class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    

                    
  <li class="mt-1">
    <a href="/guide/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Guide
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="/about/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            About
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="/articles/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Articles
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="/categories/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Categories
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="/tags/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Tags
        </p>
    </a>
</li>




                    

                </ul>
                
                

            </div>
        </label>
    </div>
</div>




<script>
    (function () {
        var $mainmenu = $('.main-menu');
        var path = window.location.pathname;
        $mainmenu.find('a[href="' + path + '"]').each(function (i, e) {
            $(e).children('p').addClass('active');
        });
    })();
</script>


  </div>
</div>
<script>
  window.addEventListener('scroll', function (e) {
    var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
    var background_blur = document.getElementById('menu-blur');
    background_blur.style.opacity = (scroll / 300);
  });
</script>

  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<article>
  
  
  
  
  
  




    
    <div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom"
    style="background-image:url(/articles/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9F%A5%E8%AF%86%E5%85%A8%E6%99%AF/featured_hu9027764350102079116.jpg);">
    


    <div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal">
    </div>
    <div
        class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal">
    </div>
</div>

<div id="background-blur" class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div>
<script>
    window.addEventListener('scroll', function (e) {
        var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
        var background_blur = document.getElementById('background-blur');
        background_blur.style.opacity = (scroll / 300)
    });
</script>

  
  

  <header id="single_header" class="mt-5 max-w-prose">
    
    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      大模型微调知识全景
    </h1>
    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      





  
  







  

















  



<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2024-12-05T10:00:40&#43;08:00">2024-12-05</time><span class="px-2 text-primary-500">&middot;</span>


<script type="text/javascript" src="/js/zen-mode.min.63c8a202661f4a2063fdc2706685d668e8ea3da613da2224e9da527e5876e4f53dcac39ab60732626fb4151feae5d430d0cf44731e5d3c726522fcc1519c1547.js" integrity="sha512-Y8iiAmYfSiBj/cJwZoXWaOjqPaYT2iIk6dpSflh25PU9ysOatgcyYm&#43;0FR/q5dQw0M9Ecx5dPHJlIvzBUZwVRw=="></script>

<span class="mb-[2px]">
    <span id="zen-mode-button"
          class="text-lg hover:text-primary-500"
          title="Enable zen mode"
          data-title-i18n-disable="Enable zen mode"
          data-title-i18n-enable="Disable zen mode">
        <span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="50px" height="50px">
    <path fill="currentColor" d="M 12.980469 4 C 9.1204688 4 5.9804688 7.14 5.9804688 11 L 6 26 L 9.9804688 26 L 9.9804688 11 C 9.9804688 9.35 11.320469 8 12.980469 8 L 40.019531 8 C 41.679531 8 43.019531 9.35 43.019531 11 L 43.019531 39 C 43.019531 40.65 41.679531 42 40.019531 42 L 29 42 C 29 43.54 28.420938 44.94 27.460938 46 L 40.019531 46 C 43.879531 46 47.019531 42.86 47.019531 39 L 47.019531 11 C 47.019531 7.14 43.879531 4 40.019531 4 L 12.980469 4 z M 7 28 C 4.794 28 3 29.794 3 32 L 3 42 C 3 44.206 4.794 46 7 46 L 23 46 C 25.206 46 27 44.206 27 42 L 27 32 C 27 29.794 25.206 28 23 28 L 7 28 z M 7 32 L 23 32 L 23.001953 42 L 7 42 L 7 32 z"/>
</svg>
  </span>

</span>
    </span>
</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    计算机
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/llm/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    LLM
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    模型微调
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    论文精读
  </span>
</span>
  </span>
  
  
  
  
</div>




    </div>

    
    
    
    
    

    

    

  </header>
  
  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
    
     <div
      class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8">
      <div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]">

         <details open id="TOCView"
  class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#一大模型开发全流程">一、大模型开发全流程</a></li>
    <li><a href="#二什么是大模型微调">二、什么是大模型微调</a></li>
    <li><a href="#三为什么需要大模型微调">三、为什么需要大模型微调</a></li>
    <li><a href="#四大模型微调的方法有哪些">四、大模型微调的方法有哪些</a>
      <ul>
        <li><a href="#41-fft-的优缺点">4.1 FFT 的优缺点</a></li>
        <li><a href="#42-peft-的优缺点">4.2 PEFT 的优缺点</a></li>
        <li><a href="#43-peft-的分类">4.3 PEFT 的分类</a></li>
      </ul>
    </li>
    <li><a href="#五各类微调方法的原理是什么">五、各类微调方法的原理是什么</a>
      <ul>
        <li><a href="#51-in-context-learning">5.1 In-Context Learning</a></li>
        <li><a href="#52-soft-prompt-tuning">5.2 Soft Prompt Tuning</a></li>
        <li><a href="#53-prefix-tuning">5.3 Prefix Tuning</a></li>
        <li><a href="#54-adapter-tuning">5.4 Adapter Tuning</a></li>
        <li><a href="#55-lora">5.5 LoRA</a></li>
        <li><a href="#56-qlora">5.6 QLoRA</a></li>
        <li><a href="#57-总结">5.7 总结</a></li>
      </ul>
    </li>
    <li><a href="#六参考资料">六、参考资料</a></li>
  </ul>
</nav>
  </div>
</details>
<details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden">
  <summary
    class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#一大模型开发全流程">一、大模型开发全流程</a></li>
    <li><a href="#二什么是大模型微调">二、什么是大模型微调</a></li>
    <li><a href="#三为什么需要大模型微调">三、为什么需要大模型微调</a></li>
    <li><a href="#四大模型微调的方法有哪些">四、大模型微调的方法有哪些</a>
      <ul>
        <li><a href="#41-fft-的优缺点">4.1 FFT 的优缺点</a></li>
        <li><a href="#42-peft-的优缺点">4.2 PEFT 的优缺点</a></li>
        <li><a href="#43-peft-的分类">4.3 PEFT 的分类</a></li>
      </ul>
    </li>
    <li><a href="#五各类微调方法的原理是什么">五、各类微调方法的原理是什么</a>
      <ul>
        <li><a href="#51-in-context-learning">5.1 In-Context Learning</a></li>
        <li><a href="#52-soft-prompt-tuning">5.2 Soft Prompt Tuning</a></li>
        <li><a href="#53-prefix-tuning">5.3 Prefix Tuning</a></li>
        <li><a href="#54-adapter-tuning">5.4 Adapter Tuning</a></li>
        <li><a href="#55-lora">5.5 LoRA</a></li>
        <li><a href="#56-qlora">5.6 QLoRA</a></li>
        <li><a href="#57-总结">5.7 总结</a></li>
      </ul>
    </li>
    <li><a href="#六参考资料">六、参考资料</a></li>
  </ul>
</nav>
  </div>
</details>

<script>

  var margin = 200;
  var marginError = 50;

  (function () {
    var $window = $(window);
    var $toc = $('#TOCView');
    var tocHeight = $toc.height();

    function onResize() {
      var windowAndMarginHeight = $window.height() - margin;
      if(tocHeight >= windowAndMarginHeight) {
        $toc.css("overflow-y", "scroll")
        $toc.css("max-height", (windowAndMarginHeight + marginError) + "px")
      } else {
        $toc.css("overflow-y", "hidden")
        $toc.css("max-height", "9999999px")
      }
    }

    $window.on('resize', onResize);
    $(document).ready(onResize);
  })();



  (function () {
    var $toc = $('#TableOfContents');
    if ($toc.length > 0) {
      var $window = $(window);

      function onScroll() {
        var currentScroll = $window.scrollTop();
        var h = $('.anchor');
        var id = "";
        h.each(function (i, e) {
          e = $(e);
          if (e.offset().top - $(window).height()/3 <= currentScroll) {
            id = decodeURIComponent(e.attr('id'));
          }
        });
        var active = $toc.find('a.active');      
        if (active.length == 1 && active.eq(0).attr('href') == '#' + id) return true;

        active.each(function (i, e) {
          
            $(e).removeClass('active');
          
        });
        $toc.find('a[href="#' + id + '"]').addClass('active')
        $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
          $(e).children('a').parents('ul').show();          
        });
      }

      $window.on('scroll', onScroll);
      $(document).ready(function () {
        
        onScroll();
      });
    }
  })();


</script>
   </div>
      </div>
      

      <div class="min-w-0 min-h-0 max-w-fit">
        
        


        <div class="article-content max-w-prose mb-20">
          

<h2 class="relative group">一、大模型开发全流程 
    <div id="%E4%B8%80%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%85%A8%E6%B5%81%E7%A8%8B" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E4%B8%80%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%85%A8%E6%B5%81%E7%A8%8B" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>当我们训练大模型时，一般会经过 <strong>pre-training</strong> 和 <strong>post-training</strong> 两个阶段。其中，pre-training 阶段一般会先使用海量数据来训练 base 大模型，再通过增量预训练来为模型注入领域知识；而 post-training 阶段则主要包括监督微调和偏好对齐两个步骤，使我们训练的大模型能够更好地适应某些特定的任务，并符合人类的表达习惯和价值观。</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/training-step.png" alt="1" />
      
    </figure>
</p>
<p><strong>pre-training：</strong></p>
<ul>
<li><strong>预训练（Pre-Training）</strong>：利用海量数据、大量算力通过无监督训练得到基座模型。预训练后的模型具备强大的语言生成能力，但由于它主要是无监督训练的结果，可能不会直接适应具体的任务（如问答、对话），需要进一步的微调；</li>
<li><strong>增量预训练（Continued Pre-Training）</strong>: 一般垂直大模型是基于通用基座大模型进行二次的训练，为了给模型注入领域知识，就需要用领域内的语料进行继续预训练。</li>
</ul>
<p><strong>post-training：</strong></p>
<ul>
<li><strong>监督微调（Supervised Fine-Tuning, SFT）</strong>：这一阶段是对基座模型进行微调，让模型能够适用于特定任务；</li>
<li><strong>偏好对齐（Reinforcement Learning from Human Feedback, RLHF）</strong>：这一阶段通过引入人类反馈进一步优化模型的生成质量，使其生成的回答更符合用户的期望和人类的价值观（对齐人类偏好）。由于直接从人类获取反馈的成本较高，通常会先训练一个奖励模型（Reward Model，RM）来代替人类打分，这样可以在 RL 的框架下实现大规模的自动优化。</li>
</ul>
<p>了解了大模型开发的整体流程，下面将重点对大模型微调相关的知识进行介绍。</p>


<h2 class="relative group">二、什么是大模型微调 
    <div id="%E4%BA%8C%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E4%BA%8C%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>大模型微调一般指的是监督微调（SFT），即使用特定下游任务的数据继续训练“预训练模型（基座模型）”，使得模型能够满足特定下游任务的性能标准。</p>
<p><strong>示例一：将大模型微调为一个可以将德语翻译为英语的模型。</strong></p>
<p>我们需要使用大量输入为德语、输出为英语的带标签数据来训练 base 大模型，这样经过微调后的大模型就可以很好地用于将德语翻译为英语的任务。</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/fine-tuning-concept.png" alt="1" />
      
    </figure>
</p>
<p><strong>示例二：开源模型为了能够直接使用，一般会提供经过问答任务微调的版本，即 Chat 模型。</strong></p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/model-name.png" alt="1" />
      
    </figure>
</p>


<h2 class="relative group">三、为什么需要大模型微调 
    <div id="%E4%B8%89%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E4%B8%89%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<ul>
<li><strong>提升特定任务表现</strong>：预训练模型虽然具有广泛的语言理解能力，但在特定任务（如情感分析、问答系统、机器翻译等）上的表现可能不尽如人意。通过在特定任务的数据上进一步训练，使模型能够更好地理解和执行该任务；</li>
<li><strong>领域适应性</strong>：预训练模型可能在一些通用领域表现良好，但在特定领域（如医学、法律、金融等）中可能难以准确理解专业术语和内容结构。通过微调，可以让模型更好地适应这些领域的语言特点，提高在这些领域中的应用效果；</li>
<li><strong>数据稀缺性</strong>：对于一些数据稀缺的任务或领域，获取大量标签数据可能比较困难。微调允许在有限的数据集上进行有效训练，从而在数据稀缺的情况下也能取得较好的性能；</li>
<li><strong>防止过拟合</strong>：预训练过程中模型可能会过度拟合于无监督学习的任务（如下一个词预测），而在特定任务中表现不佳。通过微调，可以让模型专注于特定任务的数据，这有助于减少过拟合的风险，提高模型在该任务上的泛化能力；</li>
<li><strong>成本效益</strong>：与使用 prompt 来引导模型行为相比，微调通常可以更高效地优化模型的表现。微调后的模型通常可以更直接地执行任务，减少了对复杂提示的依赖。同时，微调可以在更小的模型上实现类似于大型模型的性能，从而降低推理的计算成本和延迟，比如与使用通用的 GPT-3.5 模型相比，经过微调的小型模型（如LLaMA-7B）在成本效益上可能更具优势，尤其是在特定任务的执行上。</li>
</ul>


<h2 class="relative group">四、大模型微调的方法有哪些 
    <div id="%E5%9B%9B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9A%84%E6%96%B9%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E5%9B%9B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9A%84%E6%96%B9%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>整体上，根据微调参数量的不同，大模型微调的方法可以分为以下两类：</p>
<ul>
<li><strong>全量参数微调（Full Fine-tuning，FFT）</strong>：对预训练模型的所有参数进行更新，训练速度较慢，消耗机器资源较多；</li>
<li><strong>参数高效微调（Parameter-Efficient Fine-Tuning，PEFT）</strong>：只对部分参数进行更新，训练速度快，消耗机器资源少。</li>
</ul>
<p>此外，还有一种不需要更新模型权重就可以完成微调的方法，叫做 <strong>In-Context Learning</strong>，通过在输入的 prompt 中提供与任务相关的上下文和例子，从而让模型能够更好地了理解我们的意图。</p>
<p><strong>最新进展</strong>：</p>
<p>在 OpenAI 最新的发布会中，还提出了一种叫做 <strong>RFT（Reinforcement Fine-Tuning）</strong> 的微调技术，能够以奖励驱动的方式不断完善大模型所掌握的知识，更多细节可以参考这篇文章：<a href="https://www.datacamp.com/blog/reinforcement-fine-tuning" target="_blank"><u>What Is OpenAI&rsquo;s Reinforcement Fine-Tuning?</u></a>。</p>


<h3 class="relative group">4.1 FFT 的优缺点 
    <div id="41-fft-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#41-fft-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p><strong>优点：</strong></p>
<ul>
<li><strong>提升特定任务性能</strong>：全参微调可以对所有模型参数进行优化，从而在某些任务上获得更好的性能。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>训练成本高</strong>：全参微调所需要计算的参数量与预训练相同，随着模型规模变得越来越大，这使得在消费级硬件上进行全量微调变得不可行；</li>
<li><strong>灾难性遗忘</strong>：用特定训练数据去微调可能会把这个领域的表现变好，但也可能会把原来表现好的别的领域的能力变差。</li>
</ul>


<h3 class="relative group">4.2 PEFT 的优缺点 
    <div id="42-peft-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#42-peft-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p><strong>优点：</strong></p>
<ul>
<li><strong>降低训练成本</strong>：减少计算消耗，缩短训练时间，降低对硬件性能的要求；</li>
<li><strong>保证模型性能</strong>：针对特定下游任务，能够在一定程度上保证模型的表现和性能；</li>
<li><strong>节省存储空间</strong>：降低存储占用，大部分的参数都可以在不同任务之间共享，只需额外保存经过不同任务微调后更新的参数。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>特定任务性能有限</strong>：可能无法达到全参数微调在某些特定任务上的性能水平。</li>
</ul>
<p>因此，在实际应用中，我们应该根据具体任务的要求和可用资源情况，在服务效率和模型质量之间做出权衡。对于资源有限或对训练时间有严格要求的场景，使用 PEFT 会是一个比较好的选择；而对于需要最佳性能的任务，使用 FFT 可能会更加合适。</p>


<h3 class="relative group">4.3 PEFT 的分类 
    <div id="43-peft-%E7%9A%84%E5%88%86%E7%B1%BB" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#43-peft-%E7%9A%84%E5%88%86%E7%B1%BB" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<ul>
<li><strong>Addition-based methods</strong>：在预训练模型的基础上，新增参数或网络层，并只对这些新增的参数进行训练和更新；
<ul>
<li><strong>Adapters</strong>：在 transformer 中的 attention 和 ffn 层后增加 Adapter；</li>
<li><strong>Soft Prompts</strong>：
<ul>
<li><strong>Soft Prompt Tuning</strong>：为输入的 embedding 增加可训练的 soft prompt 参数；</li>
<li><strong>Prefix Tuning</strong>：为 transformer 的输入增加可训练的 prefix 参数；</li>
</ul>
</li>
</ul>
</li>
<li><strong>Selective methods</strong>：通过一定的算法和策略，选择预训练模型中的部分参数进行训练和更新；</li>
<li><strong>Reparametrization-based methods</strong>：利用低秩矩阵来近似地表达预训练模型需要更新的参数；
<ul>
<li><strong>LoRA</strong>；</li>
<li><strong>QLoRA</strong>；</li>
<li><strong>DLoRA</strong>；</li>
<li><strong>LongLoRA</strong>；</li>
<li><strong>GLoRA</strong>；</li>
<li><strong>AdaLoRA</strong>；</li>
<li><strong>LoRA-FA</strong>；</li>
<li><strong>VeRA</strong>；</li>
<li><strong>Delta-LoRA</strong>；</li>
<li><strong>LoRA+</strong>；</li>
<li><strong>LoRA-drop</strong>；</li>
<li>……</li>
</ul>
</li>
<li><strong>Hybrid methods</strong>：根据实际情况，可以对上述方法进行组合，从而达到更好的效果。</li>
</ul>
<p>目前比较主流的几种参数高效微调方法包括：Prompt Tuning、Prefix Tuning、LoRA、QLoRA 等。</p>
<p>论文<a href="https://arxiv.org/abs/2303.15647" target="_blank"><u>《Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning》</u></a>中展示了各类参数高效微调方法及其所属的类别，如下所示：</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/peft%E5%88%86%E7%B1%BB.png" alt="1" />
      
    </figure>
</p>
<p>该论文中还对比了各类参数高效微调方法的表现和性能，如下所示：</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/peft%E5%AF%B9%E6%AF%94.png" alt="1" />
      
    </figure>
</p>


<h2 class="relative group">五、各类微调方法的原理是什么 
    <div id="%E4%BA%94%E5%90%84%E7%B1%BB%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E4%BA%94%E5%90%84%E7%B1%BB%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88" aria-label="Anchor">#</a>
    </span>        
    
</h2>


<h3 class="relative group">5.1 In-Context Learning 
    <div id="51-in-context-learning" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#51-in-context-learning" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p><strong>核心原理：</strong></p>
<p>当我们无法直接获取到模型并修改其权重（比如：直接通过 API 或用户接口访问模型）时，就可以使用 In-Context Learning 的方式来让模型更好地适应于特定的任务。</p>
<p>In-Context Learning 通过在输入的 prompt 中提供与任务相关的上下文和例子，从而让模型能够基于我们提供的上下文，更好地生成我们期望得到的结果。</p>
<blockquote>
<p>&ldquo;Based on intuition from prompting, we believe that having a proper context can steer the LLM without changing its parameters.&rdquo;</p>
</blockquote>
<p><strong>示例：将大模型微调为一个可以将德语翻译为英语的模型。</strong></p>
<p>我们在输入的上下文中给出一些将德语翻译为英语的例子，然后再输入一句德语，这样模型就能更好地理解我们的意图，知道现在要做的是将输入的德语翻译为对应的英语。</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/in-context.png" alt="1" />
      
    </figure>
</p>
<p><strong>优点：</strong></p>
<ul>
<li>当我们没有足够的带标签数据用于监督微调时，通过 In-Context Learning，只需少量的样例，就能提升模型对于特定任务的表现；</li>
<li>当我们无法直接获取到模型并修改其权重时，通过 In-Context Learning，无需额外对模型进行微调，就可以快速地进行尝试和验证。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>相比于直接更新模型的权重进行微调，In-Context Learnin 的效果有限，模型在特定任务上的表现上不如 FFT 和 PEFT。</li>
</ul>


<h3 class="relative group">5.2 Soft Prompt Tuning 
    <div id="52-soft-prompt-tuning" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#52-soft-prompt-tuning" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p><strong>核心原理：</strong></p>
<p>Soft Prompt Tuning 可以看作是 Prefix Tuning 的简化版本，它给每个任务定义了自己的 soft prompt，并将其拼接到数据上作为输入（在输入 embedding 层加入一段定长的可训练的向量，在微调的时候只更新 soft prompt 这部分的参数）。</p>
<p>示例代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">EmbeddingLayer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">([</span><span class="n">soft_prompt_tensor</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">seq_len</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span></code></pre></div><blockquote>
<p>其中，<code>soft_prompt_tensor</code> 具有与 embedded inputs 同样的特征维度，将两者拼接过后，就相当于是增加了输入的长度。</p>
</blockquote>


<h3 class="relative group">5.3 Prefix Tuning 
    <div id="53-prefix-tuning" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#53-prefix-tuning" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p><strong>核心原理：</strong></p>
<p>Prefix Tuning 通过对输入数据增加前缀（prefix）来做微调，即在输入 token 之前构造一段任务相关的 virtual tokens 作为 prefix，训练的时候只更新 prefix 这部分的参数，每个下游任务都可以单独训练一套 prefix token。</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/prefix-tuning.png" alt="1" />
      
    </figure>
</p>
<p>示例代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">transformer_block_with_prefix</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">soft_prompt</span> <span class="o">=</span> <span class="n">FullyConnectedLayers</span><span class="p">(</span><span class="n">soft_prompt</span><span class="p">)</span>  <span class="c1"># prefix</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">([</span><span class="n">soft_prompt</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">seq_len</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">SelfAttention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">residual</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">FullyConnectedLayers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">residual</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span>
</span></span></code></pre></div><p><strong>为什么增加 prefix 可以影响模型生成的结果？</strong></p>
<p>感性地理解一下，prefix 的作用是引导模型提取输入中的特定信息，进而更好地生成结果。</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/prefix-tuning-3.png" alt="1" />
      
    </figure>
</p>
<p>另外，我们还可以针对不同的下游任务，训练不同的 prefix 并对其进行保存。这样当我们需要切换不同的下游任务时，只需要加载不同的 prefix 参数，就可以实现模型功能的快速切换。</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/prefix-tuning-2.png" alt="1" />
      
    </figure>
</p>
<p><strong>缺点：</strong></p>
<ul>
<li>微调的效果存在上限，模型的表现并不一定会随着 prefix 长度的增加而提高；</li>
<li>由于模型的输入长度一般是固定的，而增加了 prefix 之后，留给原始文字数据的空间就少了，因此可能会降低原始文字中 prompt 的表达能力。</li>
</ul>


<h3 class="relative group">5.4 Adapter Tuning 
    <div id="54-adapter-tuning" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#54-adapter-tuning" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p><strong>核心原理：</strong></p>
<p>Adapter Tuning 通过在 transformer 中的 multi-head self-attention 和 fully connected layers 后增加 Adapter 进行微调。其中，Adapter 中的第一个 fully connected layer 将高维的输入映射为了一个低维的表示，第二个 fully connected layer 再将其映射回高维的空间中，这样就能有效降低训练时需要更新的参数量。</p>
<p>微调时，只更新 Adapter 部分的权重，原模型的参数是冻结的。</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/adapter-method.png" alt="1" />
      
    </figure>
</p>
<blockquote>
<p>注意：新增的 Adapter 与原模型中的层是顺序串行的关系。</p>
</blockquote>
<p>示例代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">transformer_block_with_adapter</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">SelfAttention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">FullyConnectedLayers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Adapter</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">residual</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">FullyConnectedLayers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">FullyConnectedLayers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Adapter</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">residual</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span>
</span></span></code></pre></div><p><strong>缺点：</strong></p>
<ul>
<li>添加了 Adapter 后，模型整体的层数变深，会拖慢模型训练和推理的速度。</li>
</ul>
<p><strong>小结：</strong></p>
<ul>
<li>FFT 成本太高；</li>
<li>Prefix Tuning 难训且会减少原始训练数据中的有效文字长度；</li>
<li>Adapter Tuning 存在训练和推理延迟。</li>
</ul>
<p>为了解决以上问题，LoRA 系列微调方法便应运而生了。</p>


<h3 class="relative group">5.5 LoRA 
    <div id="55-lora" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#55-lora" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>关于 LoRA（Low-Rank Adaptation，低秩适配器）的相关原理，请参考我之前写的这篇文章：</p>

<section class="space-y-10 w-full">
    
    
</section>


<h3 class="relative group">5.6 QLoRA 
    <div id="56-qlora" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#56-qlora" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p><strong>核心原理：</strong></p>
<p>QLoRA（Quantized LoRA）的核心工作其实是模型量化，通过将预训练模型进行 NF4 量化，再结合 LoRA 的方式进行微调，可以大幅减少训练时显存的占用。</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/qlora.png" alt="1" />
      
    </figure>
</p>
<p>QLoRA 有一个 NF4 的存储数据类型和 BF16 的计算数据类型。在进行前向和反向传播时，我们需要将存储数据类型反量化为计算数据类型，但是计算梯度时我们只计算添加的适配器的梯度，这一点和 LoRA 是一致的。</p>
<ul>
<li>预训练模型的参数：进行 NF4 量化；</li>
<li>LoRA 的参数：保持 BF16 的精度。</li>
</ul>
<p><strong>核心工作：</strong></p>
<ul>
<li><strong>四位标准浮点数量化（4-bit Normal Float Quantization）</strong>：结合了分位数量化和分块量化；</li>
<li><strong>双重量化（Double Quantization）</strong>：对模型进行了两次量化，其中第二次量化只作用在第一次量化产生的量化常数上，可以进一步节约显存占用；</li>
<li><strong>分页优化（Paged Optimizer）</strong>：使用 CPU 内存代替 GPU 显存保存部分梯度参数。</li>
</ul>
<p><strong>优缺点：</strong></p>
<ul>
<li>优点：显存占用下降。由于原模型参数经过了量化，在计算时占用的内存减少了；</li>
<li>缺点：训练时间增加。由于引入了量化和反量化的计算过程，在训练时需要消耗更多的时间。</li>
</ul>
<p><strong>量化分位数的计算：</strong></p>
<ol>
<li>根据每个块的特征的绝对值的最大值，我们为每个块保存一个量化常数（每个块中的特征取绝对值后的最大值）；</li>
<li>计算每个张量的量化值（实际值/该块的量化常数）；</li>
<li>在 Q（normal_map）中找到与每个张量最接近的值，并将其量化为该值对应的索引值。</li>
</ol>
<p><code>normal_map</code> 的计算：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_normal_map</span><span class="p">(</span><span class="n">offset</span><span class="o">=</span><span class="mf">0.9677083</span><span class="p">,</span> <span class="n">use_extra_value</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">use_extra_value</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># one more positive value, this is an asymmetric type</span>
</span></span><span class="line"><span class="cl">        <span class="n">v1</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">9</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="c1"># 正数部分</span>
</span></span><span class="line"><span class="cl">        <span class="n">v2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="mi">256</span><span class="o">-</span><span class="mi">15</span><span class="p">)</span> <span class="c1">## we have 15 non-zero values in this data type</span>
</span></span><span class="line"><span class="cl">        <span class="n">v3</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">8</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="c1">#负数部分</span>
</span></span><span class="line"><span class="cl">        <span class="n">v</span> <span class="o">=</span> <span class="n">v1</span> <span class="o">+</span> <span class="n">v2</span> <span class="o">+</span> <span class="n">v3</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">v1</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">8</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">v2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="mi">256</span><span class="o">-</span><span class="mi">14</span><span class="p">)</span> <span class="c1">## we have 14 non-zero values in this data type</span>
</span></span><span class="line"><span class="cl">        <span class="n">v3</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">8</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">v</span> <span class="o">=</span> <span class="n">v1</span> <span class="o">+</span> <span class="n">v2</span> <span class="o">+</span> <span class="n">v3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span><span class="o">.</span><span class="n">values</span>
</span></span><span class="line"><span class="cl">    <span class="n">values</span> <span class="o">/=</span> <span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">values</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">256</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">values</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Q</span> <span class="o">=</span> <span class="n">create_normal_map</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Q = [-1.0, -0.6961928009986877, -0.5250730514526367, -0.39491748809814453, -0.28444138169288635, -0.18477343022823334, -0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725,0.24611230194568634, 0.33791524171829224, 0.44070982933044434, 0.5626170039176941, 0.7229568362236023, 1.0]</span>
</span></span></code></pre></div><p><strong>示例：</strong></p>
<p>假设一个张量有 16 个值，被分成了 4 块：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">input_blocked_tensor</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">1.28645003578589</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.817660483275528</span><span class="p">,</span> <span class="mf">9.889441349505042</span><span class="p">,</span> <span class="mf">0.010208034676132627</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                        <span class="p">[</span><span class="o">-</span><span class="mf">15.009014631551885</span><span class="p">,</span> <span class="mf">1.4136255086268115</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.815595761491153</span><span class="p">,</span> <span class="mf">10.766760590950263</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                        <span class="p">[</span><span class="o">-</span><span class="mf">0.731406153917959</span><span class="p">,</span> <span class="mf">3.468224595908726</span><span class="p">,</span> <span class="mf">2.445252541840315</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.970824523299282</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                        <span class="p">[</span><span class="o">-</span><span class="mf">9.641638854625175</span><span class="p">,</span> <span class="mf">7.696158363188889</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.323939281255154</span><span class="p">,</span> <span class="mf">5.97160401402024</span><span class="p">]]</span>
</span></span></code></pre></div><p>根据每个块的特征的绝对值的最大值，我们为每个块保存一个量化常数，它的计算方式是每个块中特征的绝对值中最大的那个：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">c1</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="o">|-</span><span class="mf">1.28645003578589</span><span class="o">|</span><span class="p">,</span> <span class="o">|-</span><span class="mf">1.817660483275528</span><span class="o">|</span><span class="p">,</span> <span class="o">|</span><span class="mf">9.889441349505042</span><span class="o">|</span><span class="p">,</span> <span class="o">|</span><span class="mf">0.010208034676132627</span><span class="o">|</span><span class="p">)</span> <span class="o">=</span> <span class="mf">9.889441349505042</span>
</span></span><span class="line"><span class="cl"><span class="n">c2</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="o">|-</span><span class="mf">15.009014631551885</span><span class="o">|</span><span class="p">,</span> <span class="o">|</span><span class="mf">1.4136255086268115</span><span class="o">|</span><span class="p">,</span> <span class="o">|-</span><span class="mf">7.815595761491153</span><span class="o">|</span><span class="p">,</span> <span class="o">|</span><span class="mf">10.766760590950263</span><span class="o">|</span><span class="p">)</span> <span class="o">=</span> <span class="mf">15.009014631551885</span>
</span></span><span class="line"><span class="cl"><span class="n">c3</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="o">|-</span><span class="mf">0.731406153917959</span><span class="o">|</span><span class="p">,</span> <span class="o">|</span><span class="mf">3.468224595908726</span><span class="o">|</span><span class="p">,</span> <span class="o">|</span><span class="mf">2.445252541840315</span><span class="o">|</span><span class="p">,</span> <span class="o">|-</span><span class="mf">8.970824523299282</span><span class="o">|</span><span class="p">)</span> <span class="o">=</span> <span class="mf">8.970824523299282</span>
</span></span><span class="line"><span class="cl"><span class="n">c4</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="o">|-</span><span class="mf">9.641638854625175</span><span class="o">|</span><span class="p">,</span> <span class="o">|</span><span class="mf">7.696158363188889</span><span class="o">|</span><span class="p">,</span> <span class="o">|-</span><span class="mf">5.323939281255154</span><span class="o">|</span><span class="p">,</span> <span class="o">|</span><span class="mf">5.97160401402024</span><span class="o">|</span><span class="p">)</span> <span class="o">=</span> <span class="mf">9.641638854625175</span>
</span></span></code></pre></div><p>计算张量的量化值：例如第一个值 <code>-1.28645003578589</code>，它除以这个块的量化常数 <code>c1</code> 后得到 <code>-0.13008318572517502</code>，我们可以在 <code>Q</code> 中找到与它最接近的值是 <code>-0.09105003625154495</code>，这个值在 <code>Q</code> 中对应的索引是 <code>6</code>，因此这个值被量化后的值是 <code>6</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">Q</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6961928009986877</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5250730514526367</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.39491748809814453</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">     <span class="o">-</span><span class="mf">0.28444138169288635</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18477343022823334</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09105003625154495</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">     <span class="mf">0.07958029955625534</span><span class="p">,</span> <span class="mf">0.16093020141124725</span><span class="p">,</span><span class="mf">0.24611230194568634</span><span class="p">,</span> <span class="mf">0.33791524171829224</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">     <span class="mf">0.44070982933044434</span><span class="p">,</span> <span class="mf">0.5626170039176941</span><span class="p">,</span> <span class="mf">0.7229568362236023</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
</span></span></code></pre></div><p>同理我们可以得到这个输入张量所有的值量化后的结果：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="p">[[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">14</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">13</span><span class="p">]]</span>
</span></span></code></pre></div><p>在模型保存时，除了要保存量化后的值，我们还要保存每个块对应的量化常数，因为这个值在我们进行反量化时需要用到。</p>
<p>在反量化时，我们以量化结果作为索引，从 <code>Q</code> 中查找到它对应的分位数，再乘以为每个块保存的量化常数 <code>ci</code>，便可以得到最终结果。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="p">[[</span><span class="o">-</span><span class="mf">0.9004339933799617</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8273060011889755</span><span class="p">,</span> <span class="mf">9.889441349505042</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"> <span class="p">[</span><span class="o">-</span><span class="mf">15.009014631551885</span><span class="p">,</span> <span class="mf">1.1944218804231184</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.880829111886221</span><span class="p">,</span> <span class="mf">10.850869732860506</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"> <span class="p">[</span><span class="o">-</span><span class="mf">0.816793898052648</span><span class="p">,</span> <span class="mf">3.0313783372030603</span><span class="p">,</span> <span class="mf">2.2078302737800004</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.970824523299282</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"> <span class="p">[</span><span class="o">-</span><span class="mf">9.641638854625175</span><span class="p">,</span> <span class="mf">6.970488722350373</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.062564734402345</span><span class="p">,</span> <span class="mf">5.424549965245643</span><span class="p">]]</span>
</span></span></code></pre></div><p><strong>解决了什么问题？</strong></p>
<p>如果我们粗暴的使用 round 操作去映射到低精度的更近的值，我们可能造成大量的数据都被量化到同一个数上，这样特征之间的差异性在量化过程中就被丢失了。使用分位数将张量分成了大小相同的若干个块，这样我们得到更加均匀的量化特征，这也就是分位数量化。每两个分位数的中点便是模型量化到这个区间映射的值。</p>
<p><strong>双重量化：</strong></p>
<p>QLoRA 的双重量化是指对量化常数再做一次 8 bit 的量化，在进行量化常数的量化时，QLoRA 以每 256 个量化常数为一组再做一次量化。在进行反量化时我们也需要进行两次反量化才能把量化后的值还原。</p>
<p>好处：减少了存储量化常数带来的额外显存占用。</p>
<p><strong>分页优化：</strong></p>
<p>QLoRA 的分页优化其实就是当显存不足时，将保存的部分梯度检查点转移到 CPU 内存上，和计算机的内存数据转移到硬盘上的常规内存分页一个道理。</p>


<h3 class="relative group">5.7 总结 
    <div id="57-%E6%80%BB%E7%BB%93" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#57-%E6%80%BB%E7%BB%93" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p><strong>How to use and finetune pre-trained LLMs?</strong></p>
<p>总结一下，当我们经过预训练得到 base 大模型之后，还需要进行以下操作：</p>
<ol>
<li><strong>增量预训练</strong>：注入领域知识；</li>
<li><strong>监督微调</strong>：适配特定下游任务（各类微调方法百花齐放）；</li>
<li><strong>偏好对齐</strong>：使模型生成的结果符合人类偏好。</li>
</ol>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="./images/finetune-overview-1.png" alt="1" />
      
    </figure>
</p>
<!--

## 六、大模型微调的框架有哪些

- **huggingface/transformers**：提供了丰富的预训练模型和微调工具，支持大多数主流的 NLP 任务（如文本分类、序列标注、生成任务等），适合进行快速实验和生产部署；
- **huggingface/peft**：huggingface 开源的微调基础工具；
- **modelscope/ms-swift**：modelscope 开源的轻量级微调框架，以中文大模型为主，支持各类微调方法；可以通过执行脚本进行微调，也可以在代码环境中一键微调；自带微调数据集和验证数据集，可以一键完成微调和验证；
- **hiyouga/LLaMA-Factory**：全栈微调工具，支持海量模型和各种主流微调方法；支持通过脚本微调、基于 Web 端微调（使用简单）；自带基础训练数据集；除微调外，支持增量预训练和全量微调；
- **NVIDIA/Megatron-LM**：NVIDIA 开发的大模型训练框架，支持大规模的预训练和微调，适用于需要极高性能和规模的大模型训练和微调。

**总结：**

- 快速实验选择 transformers；
- 普通规模选择 LLaMA-Factory；
- 超大规模选择 Megatron-LM。

## 七、如何在生产环境中进行微调

### 7.1 微调实践

**整体架构和组件：**

![1](./images/example-1.png)

- **Helm Char**：管理集群和训练配置；
- **PyTorchJob（with multiple workers）**：执行微调（分布式训练）；
- **PVC（Persistent Volume Claim）**：存储训练数据和模型数据；
- **Secret**：管理鉴权相关配置；
- **Data Access Pod**：……。

以上实践案例是基于 Kubeflow 提供的平台和组件进行实现的，下面将对 Kubeflow 进行介绍。

### 7.2 Kubeflow

**整体介绍：**

> "Kubeflow is a community and ecosystem of open-source projects to address each stage in the machine learning (ML) lifecycle with support for best-in-class open source tools and frameworks. Kubeflow makes AI/ML on Kubernetes simple, portable, and scalable."

![1](./images/kubeflow-1.png)

Kubeflow 包括：

- **Kubeflow Platform**：AI 模型开发部署全流程工作平台；
- **Standalone Kubeflow Components**：可独立使用的各类组件。

Kubeflow Platform：

> "The Kubeflow Platform refers to the full suite of Kubeflow components bundled together with additional integration and management tools. Using Kubeflow as a platform means deploying a comprehensive ML toolkit for the entire ML lifecycle."

Standalone Kubeflow Components：

> "The Kubeflow ecosystem is composed of multiple open-source projects that address different aspects of the ML lifecycle. Many of these projects are designed to be usable both within the Kubeflow Platform and independently. These Kubeflow components can be installed standalone on a Kubernetes cluster. It provides flexibility to users who may not require the full Kubeflow Platform capabilities but wish to leverage specific ML functionalities such as model training or model serving."

Kubeflow Overview Diagram：

![1](./images/kubeflow-2.svg)

Kubeflow Ecosystem：

![1](./images/kubeflow-3.svg)

**使用 Kubeflow 进行微调：**

> "Once user executes train API, Training Operator creates PyTorchJob with appropriate resources to fine-tune LLM."
>
> "Storage initializer InitContainer is added to the PyTorchJob worker 0 to download pre-trained model and dataset with provided parameters."
>
> "PVC with ReadOnlyMany access mode attached to each PyTorchJob worker to distribute model and dataset across Pods."

![1](./images/kubeflow-5.svg)

> "The [<u>PyTorchJob</u>](https://www.kubeflow.org/docs/components/training/user-guides/pytorch/) is a Kubernetes custom resource to run PyTorch training jobs on Kubernetes. The Kubeflow implementation of the PyTorchJob is in the training-operator."

-->


<h2 class="relative group">六、参考资料 
    <div id="%E5%85%AD%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E5%85%AD%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<ul>
<li><a href="https://arxiv.org/abs/2303.15647" target="_blank"><u>Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning</u></a></li>
<li><a href="https://arxiv.org/abs/2101.00190" target="_blank"><u>Prefix-Tuning: Optimizing Continuous Prompts for Generation</u></a></li>
<li><a href="https://arxiv.org/abs/2106.09685" target="_blank"><u>LoRA: Low-Rank Adaptation of Large Language Models</u></a></li>
<li><a href="https://book.douban.com/subject/33437381/" target="_blank"><u>李航《统计学习方法》</u></a></li>
<li><a href="https://arxiv.org/abs/2305.14314" target="_blank"><u>QLoRA: Efficient Finetuning of Quantized LLMs</u></a></li>
<li><a href="https://medium.com/@averyaveavi/%E6%B7%BA%E8%AB%87deeplearning%E7%9A%84%E6%B5%AE%E9%BB%9E%E6%95%B8%E7%B2%BE%E5%BA%A6fp32-fp16-tf32-bf16-%E4%BB%A5llm%E7%82%BA%E4%BE%8B-9bfb475e50be" target="_blank"><u>浅谈 DeepLearning 的浮点数精度 FP32/FP16/TF32/BF16……</u></a></li>
<li><a href="https://arxiv.org/abs/2309.12307" target="_blank"><u>LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models</u></a></li>
<li><a href="https://magazine.sebastianraschka.com/p/new-llm-pre-training-and-post-training" target="_blank"><u>New LLM Pre-training and Post-training Paradigms</u></a></li>
<li><a href="https://magazine.sebastianraschka.com/p/finetuning-large-language-models?utm_source=publication-search" target="_blank"><u>Finetuning Large Language Models</u></a></li>
<li><a href="https://magazine.sebastianraschka.com/p/using-and-finetuning-pretrained-transformers?utm_source=publication-search" target="_blank"><u>Using and Finetuning Pretrained Transformers</u></a></li>
<li><a href="https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms?utm_source=publication-search" target="_blank"><u>Practical Tips for Finetuning LLMs Using LoRA</u></a></li>
<li><a href="https://qiankunli.github.io/2023/10/29/llm_finetune_theory.html" target="_blank"><u>LLM 微调理论</u></a></li>
<li><a href="https://www.lixueduan.com/posts/ai/04-finetune-concept/" target="_blank"><u>GPT 是如何炼成的：大模型微调基础概念指北</u></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/646831196" target="_blank"><u>图解大模型微调系列之：大模型低秩适配器 LoRA（原理篇）</u></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/654897296" target="_blank"><u>图解大模型微调系列之：大模型低秩适配器 LoRA（源码解读与实操篇）</u></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/990958034" target="_blank"><u>图解 Fine-tuning：LoRA 系列微调技术概述</u></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/666234324" target="_blank"><u>QLoRA（Quantized LoRA）详解</u></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/659226557" target="_blank"><u>LongLoRA - 高效微调长上下文的 LLMs</u></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/658043624" target="_blank"><u>LLM 长 context 微调技巧 - LongLora</u></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/8954237216" target="_blank"><u>LoRA、QLoRA、LoRA+、LongRA、DoRA、MaLoRA、GaLore方案都知道吗？</u></a></li>
<li><a href="https://qiankunli.github.io/2024/07/28/llm_finetune_practice.html" target="_blank"><u>LLM 微调实践</u></a></li>
<li><a href="https://huggingface.co/blog/dmsuehir/llama2-fine-tuning-k8s" target="_blank"><u>Fine Tuning a LLM Using Kubernetes with Intel® Xeon® Scalable Processors</u></a></li>
<li><a href="https://www.kubeflow.org/docs/components/training/user-guides/fine-tuning/" target="_blank"><u>How to Fine-Tune LLMs with Kubeflow</u></a></li>
<li><a href="https://www.kubeflow.org/docs/components/training/reference/fine-tuning/" target="_blank"><u>LLM Fine-Tuning with Training Operator - Architecture</u></a></li>
<li><a href="https://www.kubeflow.org/docs/components/training/explanation/fine-tuning/" target="_blank"><u>LLM Fine-Tuning with the Training Operator</u></a></li>
</ul>

          
          
          
        </div>
        
        

          
            
            
<div class="flex author">
  
    
    
      
    
    
      
        
      
      <img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width="96" height="96"
      alt="Shanshan Shen" src="/images/logo_hu9373694138991197219.jpg" />
    
  
  <div class="place-self-center">
    
    <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
      Author
    </div>
    <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
      Shanshan Shen
    </div>
    
    
    <div class="text-sm text-neutral-700 dark:text-neutral-400">A software engineer focusing on LLM/VLM inference engine and GPU/NPU computing.</div>
    
    <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://github.com/shen-shanshan"
          target="_blank"
          aria-label="Github"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>

</span></a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://www.zhihu.com/people/sss-53-26"
          target="_blank"
          aria-label="Zhihu"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M170.5 148.1v217.5l23.4 0 7.7 26.4 42-26.4h49.5V148.1H170.5zm97.8 193.9h-27.9l-27.9 17.5-5.1-17.5-11.9 0V171.8h72.8v170.3zm-118.5-94.4H97.5c1.7-27.1 2.2-51.6 2.2-73.5h51.2s2-22.6-8.6-22.3h-88.5c3.5-13.1 7.9-26.7 13.1-40.7 0 0-24.1 0-32.3 21.6-3.4 8.9-13.2 43.1-30.7 78.1 5.9-.6 25.4-1.2 36.8-22.2 2.1-5.9 2.5-6.7 5.1-14.5h28.9c0 10.5-1.2 66.9-1.7 73.4H20.8c-11.7 0-15.6 23.6-15.6 23.6h65.6C66.5 321.1 42.8 363.1 0 396.3c20.5 5.9 40.9-.9 51-9.9 0 0 23-20.9 35.6-69.3l54 64.9s7.9-26.9-1.2-40c-7.6-8.9-28.1-33.1-36.8-41.8L87.9 312c4.4-14 7-27.6 7.9-40.7h61.7s-.1-23.6-7.6-23.6v0zm412-1.6c20.8-25.6 45-58.6 45-58.6s-18.7-14.8-27.4-4.1c-6 8.2-36.8 48.2-36.8 48.2l19.2 14.4zm-150.1-59.1c-9-8.3-25.9 2.1-25.9 2.1s39.5 55 41.1 57.5l19.5-13.7s-25.7-37.6-34.7-45.9h0zM640 258.4c-19.8 0-130.9 .9-131.1 .9v-101c4.8 0 12.4-.4 22.9-1.2 40.9-2.4 70.1-4 87.8-4.8 0 0 12.2-27.2-.6-33.4-3.1-1.2-23.2 4.6-23.2 4.6s-165.2 16.5-232.4 18.1c1.6 8.8 7.6 17.1 15.8 19.6 13.3 3.5 22.7 1.7 49.2 .9 24.8-1.6 43.7-2.4 56.5-2.4v99.8H351.4s2.8 22.3 25.5 22.9h107.9v70.9c0 14-11.2 22-24.5 21.1-14.1 .1-26.1-1.2-41.7-1.8 2 4 6.3 14.4 19.3 21.8 9.9 4.8 16.2 6.6 26 6.6 29.6 0 45.7-17.3 44.9-45.3v-73.3h122.4c9.7 0 8.7-23.8 8.7-23.8l0 0z"/></svg>
  </span>

</span></a
        >
      
    
  </div>

</div>
  </div>
</div>

          

          

          
          <div class="mb-10"></div>
          

        

        
        

        


<h2 class="mt-8 text-2xl font-extrabold mb-10">Related</h2>
<section class="w-full grid gap-4 sm:grid-cols-2 md:grid-cols-3">
  
  

  <a href="/articles/%E5%A4%A7%E6%A8%A1%E5%9E%8B-lora-%E5%BE%AE%E8%B0%83%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">
        
        <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/articles/%E5%A4%A7%E6%A8%A1%E5%9E%8B-lora-%E5%BE%AE%E8%B0%83%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/featured_hu5669775764973143139.jpg);"></div>
        
      

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/articles/%E5%A4%A7%E6%A8%A1%E5%9E%8B-lora-%E5%BE%AE%E8%B0%83%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/">大模型 LoRA 微调原理详解</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          











  



















<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2024-11-13T17:05:40&#43;00:00">2024-11-13</time>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    计算机
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/llm/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    LLM
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    模型微调
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    论文精读
  </span>
</span>
  </span>
  
  
  
  
</div>




        </div>

        
        <div class="py-1 prose dark:prose-invert">
          
        </div>
        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
  

  <a href="/articles/%E6%88%91%E7%9A%84%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E5%90%88%E9%9B%86/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">
        
        <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/articles/%E6%88%91%E7%9A%84%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E5%90%88%E9%9B%86/featured_hu5139481705471417855.jpg);"></div>
        
      

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/articles/%E6%88%91%E7%9A%84%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E5%90%88%E9%9B%86/">我的技术博客｜合集</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          





























<div class="flex flex-row flex-wrap items-center">
  
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    计算机
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  
</div>




        </div>

        
        <div class="py-1 prose dark:prose-invert">
          
        </div>
        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
  

  <a href="/articles/ascend-aclnn-%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">
        
        <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/articles/ascend-aclnn-%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8/featured_hu9253359173625983682.jpg);"></div>
        
      

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/articles/ascend-aclnn-%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8/">Ascend aclnn 算子开发入门</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          











  



















<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2024-10-23T15:52:36&#43;00:00">2024-10-23</time>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    计算机
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-infra/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Infra
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    算子开发
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ascend/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Ascend
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/npu/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    NPU
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/cann/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    CANN
  </span>
</span>
  </span>
  
  
  
  
</div>




        </div>

        
        <div class="py-1 prose dark:prose-invert">
          
        </div>
        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
</section>

  
      </div>
     
      
      
        
        
          
          
        
      <script>
        var oid = "views_posts\\【计算机】大模型微调知识全景\\index.md"
        var oid_likes = "likes_posts\\【计算机】大模型微调知识全景\\index.md"
      </script>
      
      
      <script type="text/javascript" src="/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
      
  
    </section>
  <footer class="pt-8 max-w-prose print:hidden">

    

    
  </footer>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
  
  <div class="flex items-center justify-between">

    
    
    <p class="text-sm text-neutral-500 dark:text-neutral-400">
      &copy;
      2025
      Shanshan Shen
    </p>
    

    
    
    <p class="text-xs text-neutral-500 dark:text-neutral-400">
      
      
      Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://blowfish.page/" target="_blank" rel="noopener noreferrer">Blowfish</a>
    </p>
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js" integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

</html>
